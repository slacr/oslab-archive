The growth of a process from kernel-buffered to having friends. How shared memory works and doesn't work. Ideas for a future tomorrow today.

Distributed Computing is the buzzword here. But how does it actually work? If we talk abstractly enough, then we can say that it works by getting multiple processes to work in collusion to perform some task. 

So lets talk about multiple processes first, then we'll try to find a suitable definition for a task. 
The operating system's basic unit of measure is a process. the OS scheduler schedules processes; the OS memory manager manages a collection of process page tables. If the OS receives a request for some kernel level function to be performed, the request is made on behalf of a running process. In systems like linux, this is a rather immutable fact. Enter fork(). Fork() is a way for a process to spawn a new process, with it's own process table, in the middle of its execution. When the fork()ed process is spawned, the kernel replicates all of the data in memory for the originating process to a new set of memory addresses for the fork()ed process to work with. This includes all of the instruction set and data that the parent had. Since the parent and child have unique process id's, the same code can be conditioned trivially to ensure that these two processes are working on independent execution sequences. 

But a couple of complications with the basic fork() approach can be seen rather easily: 1) If the child process doesn't really need to work on all the data that the parent had allocated before the fork(), then there's a potential for a big waste of memory allocation; 2) And if the child does need to work on the data, what if they need to work on the same data as the parent, not just a copy, but the exact same data? Let's take these in turn.

1) To start with a talk about the solution to this first question, let's get a more exact definition for the layout of a process, what it means to copy a process, and how the OS determines which parts of the process are to be copied in relation to one another. Before a process begins running, it is an executable, or binary, file. Binary files are broken up into segments determined by what's called the Executable and Linkable Format. The segmentation of a binary file allows the executable as a whole to be non-contiguously, or even partially, loaded into memory without a loss of continuity by simply providing pointers to the memory location of the next segment address. With this specification we can see that copying the memory space of a process can be done by iterating through these pointers, and replicating both the sequence and data to another block or set of pages in memory. If the goal is to avoid the replication of data needlessly, then all that is needed is a way to distinguish which segments are needed and which are not. The simplest approach is known as the COPY_ON_WRITE strategy. In this strategy, when a child is spawned, no replication of data is done. Instead, the child is provided with the pointers to the same memory addresses as the parent. If, at any time in execution, either the parent or child makes a write request to a shared memory address, that particular address is replicated to a new location, the write is performed, and that process is given the new address pointer to prevent modifying the other's memory space.

We can see that this simple explanation of the COPY_ON_WRITE approach satisfies 1), but, since this strategy strictly enforces non-squashing of data by either process, it in no way accounts for 2). So let's turn to it, then.

2) As we said earlier, the basic unit of the OS is the process. This means that when the OS assigns addressable memory, it is looking at the permissions and allocations of a process as a whole. Because of this, the intuitive solution is to have a single process working in parallel with itself, executing multiple instruction sequences concurrently, without the OS looking at these sequences as independent process executions. This is called threading. Threading is a convenient way to allow a process to spawn multiple execution chains, similar to fork(), without the overhead of creating a wholly new process. Since the threads are members of the same process, they all have rights to the addressable memory of the process that spawned them. This means that they can see each other's writes. 

Threading clearly satisfies 2), but is not the only way. Another foundational approach is the use of pipes. As is in keeping with the Unix tradition, pipes are built on top of the idea of the file. Pipes afford a process the opportunity to treat the data that it works with in a similar manner to how a process works with a file, which means that the data itself becomes utilizable similar to how files get utilized: as shared objects. When a process opens a pipe, it creates a new file descriptor that it can both read and write to, respectively. If, for example, after a process opened a pipe, it were to fork(), then both the parent and the child would have access to the read end and write end of the pipe, allowing them to pass data back and forth. But the benefit of pipes goes further than this. In general, a pipe opened as writable by one process can be opened as readable by another. And since pipes are treated like files by the operating system, they can be passed between processes as needed without the iterative process of copying one memory space to another.

So now we're getting somewhere. We've got a tool at our disposal that will allow processes to transfer data back and forth as needed. Pipes satisfy 1) by allowing the only shared data to be data written to the pipe file descriptor, and 2) is satisfied by allowing any permitted process the ability to read an opened pipe.  Great good alright. Sort of. While the resource of pipes gives us so much, it still only seems to lead to more questions: 3) What happens when multiple processes don't need to send data, but simply need to let each other know where they're at in an execution sequence? 4) And how does it share this data with processes that are not on the same machine?

3) So what we're talking about here is whether or not we need to generate all the metadata, conditioned handlers, and I/O associated with using file descriptors, just to have one process tell another process something that could be communicated in 1 byte or less. I mean, it is absolutely overkill to open a pipe for the sole purpose of sending flags back and forth. So what do we do? We use Signals. In Unix environments, the kernel can send a predefined set of signals to a running process. For example, if a process were to try to write to a memory address that it did not have permission to write to, the kernel would send a SIGSEGV signal to interrupt the violating process and terminate its execution. Accordingly, a process can request that the kernel send a signal to another process. Thus if a process wanted to, for example, kill another process, it could request that the kernel send that process the SIGKILL signal. These signals would then be received and handled by the process. The important thing here is that the handling of a signal can be designed at the programmatic level. Such that, if process A wishes to send an interrupt to a waiting process B to indicate that process B execute function f, then process B simply needs to have a registered handler for the interrupt from A that causes f to be executed. It's that simple!

4) Signals, Pipes, Threads, etc are all well and good, but have a fundamental limitation: they're all handled by a single operating system. That is to say, how could a pipe file descriptor be used by a remote machine? it couldn't, unless that other machine was able to address the same memory or filesystem as the local machine. See now this is where it starts to get interesting. If we want to share data or pass messages to a remote host, we need to be able to address that host. As a corrollary, if we want to pass messages to a remote process, we need to be able to both address the host of the remote process, as well as the process itself. This addressing is achieved with sockets. Each host linked up to a network has a unique network address, or IP, that can be used to identify it remotely. But in and of itself, sending a stream or packet of data to an IP address does not provide enough information to guarantee that the right process on the remote machine will recognize whether the data is intended for them or not. To circumvent this issue, we use the first portion of a network message as a header, storing what's called a port along with the source and destination IP's. The combination of an IP and a port is called a socket. With a socket, a process can send a stream or packets of bytes off to any process listening on that port on any number of remote hosts. 

Sockets themselves are not enough to ensure that the message gets where it's going. I mean, sockets are just addresses; it's not the number on your mailbox that gets the mail to your door, it's the postal service. There are two main types of sockets: connected and connectionless. both of these are used ubiquitously to handle networking layers and we'll talk about them both briefly. But before doing so, I'd like to say that there's an important vision here that we need to make sure we aren't losing track of. Namely, there exist concepts in the world that we refer to as tasks and, although we have not yet provided a definition for this concept, the execution of these concepts requires tools; what we are doing now is building up the definitions for tools that can be used to execute tasks. 

Connectionless (datagram) sockets allow packet loss. What this means is that, if A sends packet C with a datagram protocol to B, there is no guarantee that C will be received by B. As a corollary, if A sends both C and D in order to B, there is no guarantee that the order will be maintained upon receipt. This is a double-edged sword in a lot of ways. On the one hand, there is a lot of speedup that can be gotten by not requiring too much hand shaking between A and B. For example, DHCP (Dynamic Host Configuration Protocol) uses UDP (User Datagram Protocol: the main protocol used in datagram architectures) as the underlying transport layer specifically because the transactions between dhcp clients and servers can happen fast (not to mention that the dhcp protocol itself applies layers of handshaking on top of UDP that make it relatively reliable). On the other hand, not being able to provide assurance of data integrity makes it difficult to apply this architecture to protocols like HTTP, which require both well-ordered and complete messages from A to B. 

Connected (stream) sockets provide the well-ordered, two-way communication that datagram sockets do not. TCP (Transfer Control Protocol: the most common stream protocol) is an integral part of most every application that needs these guarantees (remote shells, NFS, HTTP, ...). What these applications have in common is a requisite dependency on the data integrity. This dependency is fulfilled by virtue of the definition of stream sockets: "[stream socket] Provides sequenced, reliable, bidirectional, connection-mode byte streams..." (from man 3 socket). In simple terms, a streamed socket generates a buffer on both ends of the connection, and, with each send, provides details of what data is to be expected as well as providing the expectation of confirmation of receipt.

With TCP and UDP we can start to see how remote interprocess communication can start to be put together. In fact, with the tools we've defined already, we have enough to lay a groundwork for what is meant by a Distributed Environment. Great. But, the only definition we have so far for what events might be better served by distributed computing is the implicit definition of a process that requires the tools that we've defined. Shit. So let's start with something simple: if we have a dataset of natural language that is arbitrarily large, how might we alphabetically sort that dataset rather efficiently? 

If we assume that the algorithm we use to sort a natural language dataset N has a complexity contingent on the size of N, n, then it is simple to see that, on top of the theoretical complexity C of our algorithm applied to N (C(N)), we must also incorporate into our analysis the layer of complexity L that results from the growth of n beyond the scope of our main memory. We're talking about memory thrashing and page faults mainly here. These are no joke and can really impact the efficiency of our application as n grows. So what do we do? we try to figure out a way to reduce the application of L on C(N). Effectively, we try to make n smaller. This can't be done. Obviously. Because to make n smaller is to truncate the dataset N. Instead we just want to throw more resources at the problem; the more processors and memory we can spread N around on, the more we can mitigate the effects of L on our application.

Right. Great. So. We know that there is a method to transmit data to and from a process on a remote machine. We also know that on a local machine we can move data from a process to another process via pipes/forks/threads. With both of these capabilities we encounter a really powerful opportunity: If we do it right, we can hook up an arbitrary number of machines, equipped with their own processors and memory, to do the work as a group. The key here is that we maintain the property of being able to hook more and more machines up, without any nontrivial changes to the architecture or configuration; we want our solution to be scalable.

So let's give this a shot, let's set up one process that is designed to sort a given dataset d1, and another that communicates with other processes on the network about their sorting activities over dataset di. if for each processor running on a network, we had a process monitoring network traffic related to the general task of sorting N, as well as a process dedicated to the actual sorting of its subset of N, di, we could potentially do some damage. But we can do one better, let's make the process that's doing all the network monitoring not even care about the sorting task. Instead, we'll call it a daemon and use it as a general gateway to all the machines in our network that are running similar processes. With a bit of socket programming, we can get each machine to have it's own daemon running, listening for and broadcasting on the same port any requests that need be sent/received. It may be an understatement to say 'a bit of socket programming' in this case though. In fact, it's not that trivial of a thing at all.

In this example of sorting NL, but not exclusive to it at all, we've got a lot of difficult problems to think about before we can get much further: 5) where is the data that all these machines are working with/ how will they access it? 6) How, specifically, will these daemons communicate to one another that they've worked through a particular problem, or make a request that another machine perform a task over a particular data subset? 7) If a machine fails at it's job, how will the other's find out?

Damn. I was really hoping we'd gotten through the hard parts.

So to handle 5) what we need here is a way to keep the data dynamically available to all the machines in our network. Harrumph. We actually need a couple more tools to talk about this problem: Interface Description Languages (IDL) and Remote Procedure Calls (RPC). IDL's were created way back when and popularized by the Open Group. The whole idea is that of creating a language-neutral environment for processes to communicate with. In many cases, IDL's are the very thing that make it possible for our 32 bit sparkstation running Android's Java API to be able to perform interprocess communication with our NetBSD Amiga server's Haskell apps. A good example of such a case is an RPC. RPC's are not too far off from Local Procedure calls (LPC). An LPC works by a process calling a procedure that is defined in a specific calling location. When the call is made, the calling process gives control over to the called procedure, which performs the specific actions of that procedure and then returns the values associated with the call to the calling process, at which point the calling process continues execution. With RPC's the difference is that the calling process is actually calling a stub handler, which then translates the call into and IDL request. This IDL request includes all the parameters specified by the calling process, as well as the socket to the associated procedure call's remote server. How does the stub know the socket to forward the request on? It asks a program called a portmapper which keeps tabs of all the open sockets and what RPC's they're set to handle. 

Equipped with RPC's we can do some pretty cool stuff. Like answer 5). What we'll do here is generate a system where we've got a bunch of servers that all work together to store all or part of the dataset locally, and clients that will ask these servers for all or parts of the dataset as needed. To get this to work, The servers all need to be able to communicate with one another, as well as with all the clients. These two communication channels are very different though. Server-server communications need to guarantee that all file descriptors, read/write flags, etc are being shared, as well as passing around (or at least storing the remote location of) the actual bits of a newly modified file (we call this replication). It needs these file descriptor so that when a client asks about what's up with a certain file, it can tell it what's up. It needs flags indicating the current state of the file so that, if it get's a write request from a client, it can check to make sure that no one else has a copy out that they're writing to. It needs to either have a local copy of the file or know who does, so that when someone asks to read it, it can feed it the bits or tell 'em who can. For the clients to be able to utilize the data on the servers using standard libraries and function calls, it needs to be able to maintain the file descriptors of the data locally as though the files themselves were local. With RPC's, all of these specifications get broken into separate procedures, which get written as stubs that a calling process can use to access the junk on another junkbox, verifying that the called processes are both registered with the calling process' portmapper and is, in fact, waiting for the request.

No bigs, right? Sure. It's just a Cluster File System is all. So on to 6).

Like 5), 6) is not a trivial question. 


Server communicates with client and other Servers.
Clients communicate with all Servers.
